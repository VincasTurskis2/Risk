\graphicspath{ {./Images/} }
\chapter{Design}
\section{Overview}
\label{overview}
The design for this project could be separated into two major parts - the design of the game itself and the design of the computer player. It is important to note that the design process ran essentially concurrently with the implementation of the program, as I followed a more iterative approach, rather than planning everything before starting work on the program. Additionally, the design and implementation of the game client came entirely before the design and implementation of the computer player. This meant that I had only a vague idea how the computer player is going to work or what approach it is going to take to making decisions before I finished with the game client.

The goals of my game client design were, therefore, twofold. The primary goal was to create a working game client that a user could interact with and play the game through, and that would have all the features and rules that the game requires. The secondary goal was to make my implementation extendible, so that different implementations of a computer player could be added on top of it, with little, if any, rewriting of the game client code. While I succeeded at the primary goal, and the client is fully functional, I mostly failed at the secondary goal. When implementing the computer players, multiple rewrites of the game client code were necessary, and these rewrites were one of the most time-consuming parts of this entire project.

\section{Game Client Design}
\label{gameClientDesign}
\subsection{Game Engine}
\label{gameEngine}
I chose to use Unity\footnote{Unity - https://unity.com} as the game engine for this project. This choice was mainly motivated by the fact that this was the game engine I was by far most comfortable with, and had used it for multiple previous hobby game projects. However, a strong secondary reason for my choice was the fact that \textit{Risk: Global Domination}, an officially licensed, commercially available implementation of the game, was also made using Unity as the game engine. This showed me that, not only is an implementation of Risk practical and viable in Unity, but also that the industry professionals responsible for making a commercial version of the game were evidently of the opinion that Unity is the best engine to use for their version of the game. While this did not guarantee that it was the best choice for my implementation, this fact, combined with my knowledge of the engine, led me to choosing Unity.

Other game engines that were considered were libGDX\footnote{LibGDX: https://libgdx.com/} and Godot\footnote{Godot: https://godotengine.org/}. Their main draw was the fact that this was going to be a light-weight, rudimentary implementation of the game, and that it did not perhaps need a large, fully-featured 3D game engine such as Unity. However, the lack of a GUI when developing with libGDX was too major of a downside for me. Godot, on the other hand, was only slightly lighter than Unity, and would have required me to code the game in GDScript, a language made for the Godot engine. I was wary of having to learn a brand new programming language on top of a new engine and all the other work required for this project, and therefore decided not to go with Godot.

The main effects of using Unity for this project were the ease of creating a user interface and the specifics of writing code for a Unity game. The user interface creation was made much faster by using Unity - there are serviceable default assets available to quickly put together a functioning UI, which allowed me to focus more on the implementation of the rules of the game and the computer player. The initial idea was for this quickly assembled UI to be a placeholder, however, after consultation with my project supervisor and the fact that other aspects of the project took more time and effort than expected, I ended up with that version being left in the final version of the project.

The other effect of using Unity was having to adapt to Unity's features and approach to game development. Unity uses C\#, therefore, that is what the project is coded in. For user-written C\# scripts, Unity's design suggests one should use them as components on their game objects. Specifically, most classes written for a Unity game will inherit from a class called \texttt{MonoBehaviour}, which allows for the file/script to be attached to a game object. This game object can then be placed in the game world. I represent the game board and each territory on it as game objects, meaning the classes for those aspects needed to inherit from \texttt{MonoBehaviour}. This caused some issues, such as these classes not being able to have a constructor. Instead of a constructor, Unity initializes \texttt{MonoBehaviour} subclasses itself, together with the game objects they are attached to, but it does not guarantee the order of initialization, causing some dependency issues.

\subsection{User Interaction Design}
\label{userInteractionDesign}

The main purpose of the game client, in addition to acting as a vessel for the computer player, was to allow a human player to interact with the game. This interface should allow the user to set the game up to their liking, and once the game starts, to take all the actions allowed to them by the rules. For game set-up, I created a simple main menu for the game client, allowing the user to either start a game or define a simulation (a series of games between only computer players). In both of these options, the user is allowed to add or remove players to the game, set their names and colours, and set their types (Human/MCTS/Passive). The player selection screen can be seen in figure \ref{fig:PlayerSelectMenu}. The screen for starting a simulation is very similar, except it does not ask for a color for each player, as the games will not be represented visually.


\begin{figure}[H]
\includegraphics[width=\textwidth]{player_select_menu}
\caption{A screenshot of the player selection menu}
\label{fig:PlayerSelectMenu}
\end{figure}

\begin{figure}[H]
\includegraphics[width=\textwidth]{game_screen}
\caption{A screenshot of the game screen}
\label{fig:GameScreen}
\end{figure}

After the game is launched, the player is presented with the board of Risk, seen in figure \ref{fig:GameScreen}. UI elements indicate whose turn it is, and what stage of the turn they are in (distributing the troops at the start of the game, deploying their troops, attacking, or reinforcing their territories). The human player can click on their territories in order to interact with them based on the turn stage - for example, clicking on a territory they own while the turn stage is "Deploy" will add a troop to that territory, and clicking on a territory they own and then on a territory they do not not own while the stage is "Attack" will initialize an attack. The player also has a button to end the turn stage - which eventually also ends the turn itself.

The final major feature of the game screen is the card hand display at the bottom of the screen. This shows all the cards the player has in their hand, and allows them to select cards and trade them in for troops. There is also a button to hide their cards, which is there to facilitate hot-seat playing with multiple human players on the same device - before a player ends their turn, they can hide their cards, call the next player to take their turn, end their turn, and the next player can show their own hand of cards. This makes it so that no player sees information that they are not supposed to have access to.

This user interface covers all the rules of the game, however, it has many usability issues, as the player experience was not my focus for this project. One of the issues is the fact that clicks on territories immediately commit the changes, meaning that a misclick when deploying troops is irreversible. There is also no tutorial or rule page for players that may not know the rules. These and other issues are part of possible future work on this project.

\subsection{Code Structure}
\label{codeStructure}
\begin{figure}[H]
\includegraphics[width=\textwidth]{project_class_architecture_updated}
\caption{A high-level diagram of the class structure of the project}
\label{fig:UMLDiagram}
\end{figure}

Figure \ref{fig:UMLDiagram} shows an overview of the structure of my code. The key classes of the program are:
\begin{itemize}
\item \texttt{GameState}, which represents a particular state of the game. This state is partially a facade, as some parts of the game state are delegated to other classes that the \texttt{GameState} class aggregates, such as \texttt{Map}, which contains information about all the territories, their owners and their troop counts, and \texttt{CardDeck} (not shown in the diagram), which keeps track of which territory cards have already been drawn, and what card should be drawn the next time a player requests one.
\item \texttt{GameMaster}, which processes and executes requests by players to change the game state, and keep track of other data about the game, such as the total time a game has been running.
\item \texttt{Player} and its subclasses, which represent all possible player types, and which will be talked about extensively in section \ref{computerPlayerCodeStructure}.
\end{itemize}

The flow of the game begins with \texttt{GameMaster} initializing the game board, and calling the \texttt{StartTurn()} method of the player who would make the first turn. \texttt{Player}'s \texttt{StartTurn()} method is abstract, and each subclass has its own implementation of it. The \texttt{Player} class then makes decisions about what moves to make, and executes them by creating an instance of one of the subclasses of \texttt{PlayerAction}, supplying the constructor with the appropriate arguments, and calling the \texttt{execute()} method of the new instance. The \texttt{execute()} method then performs checks whether the action is legal, and if it is, calls the appropriate methods from \texttt{GameMaster} to perform the move. After the player exhausts their moves or decides to end their turn, \texttt{GameMaster} updates the current player value in \texttt{GameState} and calls \texttt{StartTurn()} for the new current player.

In the original design (as described in the proposal in Appendix 1) \texttt{GameMaster} and \texttt{GameState} were part of the same class. However, after researching Monte Carlo tree search, it became apparent that the original design was insufficient, as in order to run the search, the game state needed to be cloned, and the existing structure of the code had many circular references that made deep-cloning impossible. After the refactoring, the unified game state class was split into \texttt{GameState}, which was now cloneable, and \texttt{GameMaster}, which is a singleton and contains a reference to a \texttt{GameState} - the state of the game currently being run.

The requirements of Monte Carlo tree search were also the reason behind changes to \texttt{PlayerAction}. Before the refactoring, all the possible actions were represented as methods in a single class called \texttt{PlayerActions} (plural). However, Monte Carlo tree search is supposed to return an action for the player to take (or, in this project's case, a list of actions). It is difficult to return methods in an OOP language like C\#, therefore, I changed the implementation of the player actions to an abstract class called \texttt{PlayerAction} (singular), with an abstract \texttt{execute()} method, and the implementation of specific actions is left to the subclass of that action. In this version, the search algorithm can return a list of \texttt{PlayerAction} objects, and the player class can iterate through this list and call \texttt{execute()} on each element.

\section{Computer Player Design}
\label{computerPlayerDesign}
\subsection{Approach}
The first question that needed to be answered in order to design a computer player is what approach said computer player will take. There were many possible approaches - from a rule-based, simple computer player, to a player utilising a search technique such as minimax, alpha-beta pruning or Monte Carlo tree search, to using machine learning or genetic algorithms. After initial research, a player using Monte Carlo tree search looked to be the most promising. Overall, search-based approaches were a good fit for this project, being more complex and requiring less expert knowledge (which I do not have) than rule-based approaches, but being easier to implement and requiring less resources than a full machine learning player would require. Out of all the search-based approaches, Monte Carlo tree search seemed to be the best suited for more complex games such as Risk, and also was the best at dealing with games with a high branching factor. Although Risk's branching factor is too high for even MCTS to handle without adjustments\cite{bauer2023artificial}, those adjustments would have to be smaller and less extreme with MCTS than with other search-based approaches.

My initial plan for the project was to make multiple computer players, each taking a different approach, and comparing their performance against each other. The primary approach would be MCTS, and the approaches to compare it to were supposed to be a rule-based computer player and a hybrid of the two. However, it soon became apparent that implementing a computer player, and specifically one that uses MCTS, is far more difficult than I had anticipated. In the end, I could only implement the hybrid approach between MCTS and rule-based techniques, and my evaluation is mostly based on my personal testing and comparisons between different iterations of the same algorithm.

\subsection{Action Pruning}
\label{actionPruning}

As previously mentioned in chapter \ref{background}, the branching factor of Risk is far too large to apply any search-based algorithm without action pruning. The primary method of action pruning I applied to my implementation of MCTS is using a rule-based approach for deploying troops and making the reinforcing move, and only using MCTS to find where to attack. The reasoning behind this decision is that the decisions behind these moves are usually rather simple and have clear rules - such as "keeping troops on borders is advantageous". There are some edge cases where a rule-based approach is insufficient, however, they do not warrant adding these moves to the search, and therefore, making the branching factor orders of magnitude larger than it would be if they kept out.

Another method of action pruning was not using chance nodes when constructing the action tree. The program creates a new node in the tree by "applying" an attack to an existing state (the node's parent), which creates a new state. Instead of using dice rolls when creating a new state, I assume each player lost a proportional amount of troops during the attack, and the attack only succeeded if the attacker started with more troops than the defender. Some literature, such as Winands, 2017 \cite{winands2017monte} and even the aforementioned Lim{\'e}r et al. 2020 \cite{limer2020monte} suggest that Risk requires the use of chance nodes, as the board state and the number of troops on each territory fully depend on the result of the dice rolls. I have decided to avoid using them regardless, as the performance of my search algorithm is very poor and requires aggressive action pruning techniques in order to be close to viable. A chance node, even a simplified or grouped one as suggested by Lim{\'e}r et al., would increase the branching factor several times.

For most of the implementation process, I assumed that the dice rolling process in Risk was balanced, and "proportional amount of troops" meant the exact same losses for both attacker and defender. I wanted to confirm this assumption, but I failed to find proof in existing literature. At this point, I wrote a simple Python script which checked every possible dice combination in a single roll (of 3 attacker dice, 2 defender dice), and how many troops each player would lose. The results of this simple simulation showed that the defender is disadvantaged in such a roll, and that on average, the defender will lose 1.17176 troops for each 1 attacker troop loss (The script and the results can be found in \texttt{/Risk/Assets/Py scripts/RiskDiceRollCalc.py}).

The final pruning strategy I use is to always move every troop into the new territory after a successful attack. Lim{\'e}r et al\cite{limer2020monte} suggests accounting for several possibilities, such as moving all or 3 troops, but I decided against doing that, as my implementation still struggles with the branching factor, and adding these options would double the branching factor.